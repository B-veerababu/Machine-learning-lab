{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/B-veerababu/Machine-learning-lab/blob/main/ML_Lab10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naïve Bayes Classifier Algorithm:**\n",
        "\n",
        "* Naïve Bayes algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems.\n",
        "\n",
        "* It is mainly used in text classification that includes a high-dimensional training dataset.\n",
        "\n",
        "* Naïve Bayes Classifier is one of the simple and most effective Classification algorithms which helps in building the fast machine learning models that can make quick predictions.\n",
        "\n",
        "* It is a probabilistic classifier, which means it predicts on the basis of the probability of an object.\n",
        "\n",
        "* Some popular examples of Naïve Bayes Algorithm are spam filtration, Sentimental analysis, and classifying articles."
      ],
      "metadata": {
        "id": "oyWIWTBey0cZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Naïve Bayes algorithm is comprised of two words Naïve and Bayes, Which can be described as:\n",
        "\n",
        "**Naïve:** It is called Naïve because it assumes that the occurrence of a certain feature is independent of the occurrence of other features. Such as if the fruit is identified on the bases of color, shape, and taste, then red, spherical, and sweet fruit is recognized as an apple. Hence each feature individually contributes to identify that it is an apple without depending on each other.\n",
        "\n",
        "**Bayes:** It is called Bayes because it depends on the principle of Bayes' Theorem."
      ],
      "metadata": {
        "id": "TRUi7fODzMt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bayes' Theorem:**\n",
        "\n",
        "Bayes' theorem is also known as **Bayes' Rule** or **Bayes' law**, which is used to determine the probability of a hypothesis with prior knowledge. It depends on the conditional probability.\n",
        "\n",
        "**The formula for Bayes' theorem is given as:**\n",
        "![image.png](data:image/png;base64,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)\n",
        "Where,\n",
        "\n",
        "P(A|B) is Posterior probability: Probability of hypothesis A on the observed event B.\n",
        "\n",
        "P(B|A) is Likelihood probability: Probability of the evidence given that the probability of a hypothesis is true."
      ],
      "metadata": {
        "id": "Q_YYe53ext2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **10. Assuming a set of Documents that need to be classified, use the naive Bayesian Classifier model to perform this task. Built - in Java classes API can be used to write the program. Calculate the accuracy, Precision and recall for your dataset.**\n"
      ],
      "metadata": {
        "id": "Z2EEGIKHuvVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import java.io.File;\n",
        "import java.io.IOException;\n",
        "```python\n",
        "import java.io.File;\n",
        "import java.io.IOException;\n",
        "import java.nio.file.Files;\n",
        "import java.nio.file.Paths;\n",
        "import java.util.*;\n",
        "\n",
        "public class NaiveBayesClassifier {\n",
        "\n",
        "    private static final String DATA_DIR = \"path/to/your/data\"; // Replace with your data directory\n",
        "    private static final String TRAIN_DIR = DATA_DIR + \"/train\";\n",
        "    private static final String TEST_DIR = DATA_DIR + \"/test\";\n",
        "\n",
        "    private Set<String> vocabulary = new HashSet<>();\n",
        "    private Map<String, Integer> classCounts = new HashMap<>();\n",
        "    private Map<String, Map<String, Integer>> wordCountsByClass = new HashMap<>();\n",
        "\n",
        "    public static void main(String[] args) throws IOException {\n",
        "        NaiveBayesClassifier classifier = new NaiveBayesClassifier();\n",
        "        classifier.train();\n",
        "        classifier.test();\n",
        "    }\n",
        "\n",
        "    public void train() throws IOException {\n",
        "        File trainDir = new File(TRAIN_DIR);\n",
        "        for (File classDir : trainDir.listFiles()) {\n",
        "            String className = classDir.getName();\n",
        "            classCounts.put(className, 0);\n",
        "            wordCountsByClass.put(className, new HashMap<>());\n",
        "\n",
        "            for (File file : classDir.listFiles()) {\n",
        "                classCounts.put(className, classCounts.get(className) + 1);\n",
        "                String content = new String(Files.readAllBytes(Paths.get(file.getPath())));\n",
        "                // Apply preprocessing here (tokenization, stop word removal, stemming/lemmatization)\n",
        "                String[] words = content.split(\"\\\\s+\");\n",
        "                for (String word : words) {\n",
        "                    vocabulary.add(word);\n",
        "                    wordCountsByClass.get(className).put(word,\n",
        "                            wordCountsByClass.get(className).getOrDefault(word, 0) + 1);\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public void test() throws IOException {\n",
        "        File testDir = new File(TEST_DIR);\n",
        "        int correctPredictions = 0;\n",
        "        int totalPredictions = 0;\n",
        "        List<String> predictedLabels = new ArrayList<>();\n",
        "        List<String> actualLabels = new ArrayList<>();\n",
        "\n",
        "        for (File classDir : testDir.listFiles()) {\n",
        "            String className = classDir.getName();\n",
        "            for (File file : classDir.listFiles()) {\n",
        "                String content = new String(Files.readAllBytes(Paths.get(file.getPath())));\n",
        "                // Apply preprocessing here (same as in training)\n",
        "                String predictedClass = classify(content);\n",
        "                predictedLabels.add(predictedClass);\n",
        "                actualLabels.add(className);\n",
        "\n",
        "                if (predictedClass.equals(className)) {\n",
        "                    correctPredictions++;\n",
        "                }\n",
        "                totalPredictions++;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        double accuracy = (double) correctPredictions / totalPredictions;\n",
        "        System.out.println(\"Accuracy: \" + accuracy);\n",
        "\n",
        "        // Calculate precision, recall using predictedLabels and actualLabels\n",
        "        // Refer to the previous response for calculation details or use external libraries\n",
        "    }\n",
        "\n",
        "    public String classify(String document) {\n",
        "        String[] words = document.split(\"\\\\s+\"); // Tokenize (adjust for preprocessing)\n",
        "        String bestClass = null;\n",
        "        double bestScore = Double.NEGATIVE_INFINITY;\n",
        "\n",
        "        for (String className : classCounts.keySet()) {\n",
        "            double score = Math.log(classCounts.get(className));\n",
        "            for (String word : words) {\n",
        "                if (vocabulary.contains(word)) {\n",
        "                    score += Math.log((wordCountsByClass.get(className).getOrDefault(word, 0) + 1) /\n",
        "                            (double)(wordCountsByClass.get(className).values().stream().mapToInt(Integer::intValue).sum() + vocabulary.size()));\n",
        "                }\n",
        "            }\n",
        "\n",
        "            if (score > bestScore) {\n",
        "                bestScore = score;\n",
        "                bestClass = className;\n",
        "            }\n",
        "        }\n",
        "        return bestClass;\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "    private static final String DATA_DIR = \"path/to/your/data\"; // Replace with your data directory\n",
        "    private static final String TRAIN_DIR = DATA_DIR + \"/train\";\n",
        "    private static final String TEST_DIR = DATA_DIR + \"/test\";\n",
        "\n",
        "    private Set<String> vocabulary = new HashSet<>();\n",
        "    private Map<String, Integer> classCounts = new HashMap<>();\n",
        "    private Map<String, Map<String, Integer>> wordCountsByClass = new HashMap<>();\n",
        "\n",
        "    public static void main(String[] args) throws IOException {\n",
        "        NaiveBayesClassifier classifier = new NaiveBayesClassifier();\n",
        "        classifier.train();\n",
        "        classifier.test();\n",
        "    }\n",
        "\n",
        "    public void train() throws IOException {\n",
        "        File trainDir = new File(TRAIN_DIR);\n",
        "        for (File classDir : trainDir.listFiles()) {\n",
        "            String className = classDir.getName();\n",
        "            classCounts.put(className, 0);\n",
        "            wordCountsByClass.put(className, new HashMap<>());\n",
        "\n",
        "            for (File file : classDir.listFiles()) {\n",
        "                classCounts.put(className, classCounts.get(className) + 1);\n",
        "                String content = new String(Files.readAllBytes(Paths.get(file.getPath())));\n",
        "                // Apply preprocessing here (tokenization, stop word removal, stemming/lemmatization)\n",
        "                String[] words = content.split(\"\\\\s+\");\n",
        "                for (String word : words) {\n",
        "                    vocabulary.add(word);\n",
        "                    wordCountsByClass.get(className).put(word,\n",
        "                            wordCountsByClass.get(className).getOrDefault(word, 0) + 1);\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public void test() throws IOException {\n",
        "        File testDir = new File(TEST_DIR);\n",
        "        int correctPredictions = 0;\n",
        "        int totalPredictions = 0;\n",
        "        List<String> predictedLabels = new ArrayList<>();\n",
        "        List<String> actualLabels = new ArrayList<>();\n",
        "\n",
        "        for (File classDir : testDir.listFiles()) {\n",
        "            String className = classDir.getName();\n",
        "            for (File file : classDir.listFiles()) {\n",
        "                String content = new String(Files.readAllBytes(Paths.get(file.getPath())));\n",
        "                // Apply preprocessing here (same as in training)\n",
        "                String predictedClass = classify(content);\n",
        "                predictedLabels.add(predictedClass);\n",
        "                actualLabels.add(className);\n",
        "\n",
        "                if (predictedClass.equals(className)) {\n",
        "                    correctPredictions++;\n",
        "                }\n",
        "                totalPredictions++;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        double accuracy = (double) correctPredictions / totalPredictions;\n",
        "        System.out.println(\"Accuracy: \" + accuracy);\n",
        "\n",
        "        // Calculate precision, recall using predictedLabels and actualLabels\n",
        "        // Refer to the previous response for calculation details or use external libraries\n",
        "    }\n",
        "\n",
        "    public String classify(String document) {\n",
        "        String[] words = document.split(\"\\\\s+\"); // Tokenize (adjust for preprocessing)\n",
        "        String bestClass = null;\n",
        "        double bestScore = Double.NEGATIVE_INFINITY;\n",
        "\n",
        "        for (String className : classCounts.keySet()) {\n",
        "            double score = Math.log(classCounts.get(className));\n",
        "            for (String word : words) {\n",
        "                if (vocabulary.contains(word)) {\n",
        "                    score += Math.log((wordCountsByClass.get(className).getOrDefault(word, 0) + 1) /\n",
        "                            (wordCountsByClass.get(className).values().stream()."
      ],
      "metadata": {
        "id": "oGkg17hZu6Ke",
        "outputId": "51a13a35-993d-4be6-f06f-aa5abdce3e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-7-d6362aebde7e>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-d6362aebde7e>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    import java.util.*;\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cTFOB-uyu6HC"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}